increased max token count per batch to 8192
Model: simple
Epochs: 3
Alpha: 0.001
Embedding dimension: 256
Heads: 4
Batch by: tokens
------------------------------------
Training with AdaptiveMaxPool1d(output_size=1) pooling
Epoch 1 Loss: 0.39
Epoch 2 Loss: 0.44
Epoch 3 Loss: 0.06
Training took 12:59 minutes
Accuracy of the AdaptiveMaxPool1d(output_size=1) pooling model: 80.18%
Training with AdaptiveAvgPool1d(output_size=1) pooling
Epoch 1 Loss: 0.03
Epoch 2 Loss: 0.00
Epoch 3 Loss: 0.00
Training took 12:39 minutes
Accuracy of the AdaptiveAvgPool1d(output_size=1) pooling model: 81.86%
