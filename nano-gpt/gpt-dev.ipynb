{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespear Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "vocab_url = \"http://qwone.com/~jason/20Newsgroups/vocabulary.txt\"\n",
    "text_url = \"http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\"\n",
    "r = requests.get(vocab_url)\n",
    "text = r.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Char to Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "data_size, vocab_size = len(text), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)} # string to index\n",
    "itos = {i:ch for i,ch in enumerate(chars)} # index to string\n",
    "encode_int = lambda x: [stoi[c] for c in x] # encode text to array of ints\n",
    "decode_int = lambda x: ''.join([itos[c] for c in x]) # decode array of ints to text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "assert encoder.decode(encoder.encode(\"Hello World\")) == \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "\n",
    "data = torch.tensor(encoder.encode(text), dtype=torch.long)\n",
    "dataset = torch.utils.data.TensorDataset(data)\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "test_size = int(0.15 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_set, test_set, val_set = random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "context_window = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With input (tensor([   66,   568,   198,   261,   620, 36902,   297, 24903]),) the target is tensor([  568,   198,   261,   620, 36902,   297, 24903,  7230])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(context_window):\n\u001b[1;32m      4\u001b[0m     context \u001b[39m=\u001b[39m x[:t\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     target \u001b[39m=\u001b[39m y[t]\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWith input \u001b[39m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m the target is \u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x = train_set[:context_window]\n",
    "y = train_set[1:context_window+1]\n",
    "for t in range(context_window):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"With input {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
